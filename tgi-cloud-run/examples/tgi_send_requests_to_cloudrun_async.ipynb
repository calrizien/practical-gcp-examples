{
  "cells": [
    {
      "cell_type": "code",
      "id": "X4WII57ssD3TcoyPzYyg5q4v",
      "metadata": {
        "tags": [],
        "id": "X4WII57ssD3TcoyPzYyg5q4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9798f6e2-7f43-4b2b-b331-2519f19051db"
      },
      "source": [
        "!uv init\n",
        "!uv add aiohttp asyncio"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Project is already initialized in `\u001b[36m/content\u001b[39m` (`pyproject.toml` file exists)\n",
            "\u001b[2mResolved \u001b[1m13 packages\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m12 packages\u001b[0m \u001b[2min 0.60ms\u001b[0m\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOTAL_CONCURRENT_REQUESTS = 30\n",
        "LLM_MODEL = \"tgi\"\n",
        "NUM_TOKENS = 128\n",
        "CR_URL = \"https://tgi-cloud-run-630458277802.europe-west4.run.app/v1/completions\" # replace with yours"
      ],
      "metadata": {
        "id": "qWDVGhCaZekp"
      },
      "id": "qWDVGhCaZekp",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import aiohttp\n",
        "import asyncio\n",
        "import time\n",
        "import numpy as np\n",
        "import random\n",
        "import nest_asyncio\n",
        "import google.auth\n",
        "import requests\n",
        "\n",
        "from google.auth.transport.requests import Request\n",
        "from google.auth import impersonated_credentials\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Service account to impersonate, you must use a impersonated SA or it won't let you get the correct token\n",
        "IMPERSONATE_SERVICE_ACCOUNT = \"project-level-cloud-run-invoke@rocketech-de-pgcp-sandbox.iam.gserviceaccount.com\"\n",
        "\n",
        "# List of question templates\n",
        "question_templates = [\n",
        "    \"How would you design an Airflow DAG to handle a daily ETL pipeline that processes data from {source} to {destination}?\",\n",
        "    \"Write an Airflow task to validate the schema of a {file_type} file stored in {storage} before processing.\",\n",
        "    \"How would you optimize an Airflow DAG that is experiencing performance bottlenecks due to {issue}?\",\n",
        "    \"Write a Python function to dynamically generate Airflow tasks based on a list of {input_parameter}.\",\n",
        "    \"How would you handle task dependencies in an Airflow DAG where {task_A} must run only if {task_B} succeeds?\",\n",
        "    \"Write an Airflow sensor to wait for a file named {file_name} to appear in {storage} before proceeding.\",\n",
        "    \"How would you configure retries and retry delays for an Airflow task that interacts with {external_service}?\",\n",
        "    \"Write a Cloud Composer DAG to orchestrate a data pipeline that processes data from {source} and loads it into {destination}.\",\n",
        "    \"How would you monitor and alert for failed tasks in an Airflow DAG running on Cloud Composer?\",\n",
        "    \"Write an Airflow task to backfill data from {start_date} to {end_date} for a specific {dataset}.\",\n",
        "    \"How would you secure sensitive information (e.g., API keys) in an Airflow DAG running on Cloud Composer?\",\n",
        "    \"Write an Airflow DAG to handle a scenario where {task} fails and needs to trigger a rollback process.\",\n",
        "    \"How would you scale an Airflow DAG to process {large_dataset} efficiently in Cloud Composer?\",\n",
        "    \"Write a Python script to automate the deployment of an Airflow DAG to a Cloud Composer environment.\",\n",
        "    \"How would you debug an Airflow DAG that is stuck in a {state} state in Cloud Composer?\",\n",
        "]\n",
        "\n",
        "# Placeholder values for dynamic question generation\n",
        "placeholders = {\n",
        "    \"source\": [\"BigQuery\", \"Google Cloud Storage\", \"Pub/Sub\", \"MySQL\", \"PostgreSQL\"],\n",
        "    \"destination\": [\"BigQuery\", \"Google Cloud Storage\", \"Dataflow\", \"Snowflake\", \"Redshift\"],\n",
        "    \"file_type\": [\"CSV\", \"JSON\", \"Parquet\", \"Avro\"],\n",
        "    \"storage\": [\"Google Cloud Storage\", \"AWS S3\", \"Azure Blob Storage\"],\n",
        "    \"issue\": [\"high task concurrency\", \"long-running tasks\", \"resource contention\"],\n",
        "    \"input_parameter\": [\"table names\", \"file paths\", \"dates\"],\n",
        "    \"task_A\": [\"data extraction\", \"data transformation\", \"data validation\"],\n",
        "    \"task_B\": [\"data loading\", \"data cleaning\", \"data aggregation\"],\n",
        "    \"external_service\": [\"BigQuery\", \"Cloud SQL\", \"REST API\"],\n",
        "    \"file_name\": [\"data.csv\", \"input.json\", \"output.parquet\"],\n",
        "    \"start_date\": [\"2023-01-01\", \"2022-12-01\", \"2023-03-15\"],\n",
        "    \"end_date\": [\"2023-01-31\", \"2022-12-31\", \"2023-03-31\"],\n",
        "    \"dataset\": [\"sales\", \"user_activity\", \"inventory\"],\n",
        "    \"task\": [\"data extraction\", \"data transformation\", \"data loading\"],\n",
        "    \"large_dataset\": [\"1TB of logs\", \"10 million rows\", \"100GB of images\"],\n",
        "    \"state\": [\"running\", \"queued\", \"failed\"],\n",
        "}\n",
        "\n",
        "def generate_question(template, placeholders):\n",
        "    \"\"\"Generate a question by replacing placeholders with random values.\"\"\"\n",
        "    for key, values in placeholders.items():\n",
        "        if f\"{{{key}}}\" in template:\n",
        "            template = template.replace(f\"{{{key}}}\", random.choice(values))\n",
        "    return template\n",
        "\n",
        "def generate(num_prompts):\n",
        "    \"\"\"Generate the specified number of unique questions.\"\"\"\n",
        "    for _ in range(num_prompts):\n",
        "        template = random.choice(question_templates)\n",
        "        yield generate_question(template, placeholders)\n",
        "\n",
        "async def get_access_token():\n",
        "    \"\"\"Fetches an OAuth2 access token using Application Default Credentials (ADC).\"\"\"\n",
        "    creds, _ = google.auth.default()\n",
        "    creds.refresh(Request())  # Ensure the token is refreshed\n",
        "    return creds.token\n",
        "\n",
        "# Generate all prompts\n",
        "all_prompts = list(generate(TOTAL_CONCURRENT_REQUESTS))\n",
        "\n",
        "async def send_request(session, index, latencies, token):\n",
        "    \"\"\"Sends an authenticated request to the Cloud Run endpoint using an identity token.\"\"\"\n",
        "\n",
        "    payload = {\n",
        "        \"model\": LLM_MODEL,\n",
        "        \"prompt\": all_prompts[index],\n",
        "        \"max_tokens\": NUM_TOKENS,\n",
        "        \"temperature\": 0.90\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {token}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        start_time = time.monotonic()\n",
        "        async with session.post(CR_URL, json=payload, headers=headers) as response:\n",
        "            end_time = time.monotonic()\n",
        "            latency = end_time - start_time\n",
        "            latencies.append(latency)\n",
        "\n",
        "            if response.status == 200:\n",
        "                return await response.text()\n",
        "            else:\n",
        "                return f\"Error: {response.status} - {await response.text()}\"\n",
        "    except Exception as e:\n",
        "        return f\"Exception: {str(e)}\"\n",
        "\n",
        "async def main():\n",
        "    \"\"\"Main function to send multiple concurrent requests to Cloud Run.\"\"\"\n",
        "    latencies = []\n",
        "\n",
        "    # Create a base credential from ADC\n",
        "    base_credentials, project_id = google.auth.default()\n",
        "\n",
        "    # Create an impersonated credential with the target service account\n",
        "    impersonated_creds = impersonated_credentials.Credentials(\n",
        "        base_credentials,\n",
        "        target_principal=IMPERSONATE_SERVICE_ACCOUNT,\n",
        "        target_scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
        "        lifetime=3600  # Token lifetime in seconds\n",
        "    )\n",
        "\n",
        "    # Obtain an ID token for the Cloud Run service (audience = Cloud Run URL)\n",
        "    request = Request()\n",
        "    # Fetch an ID token using the impersonated credentials\n",
        "    id_token_creds = impersonated_credentials.IDTokenCredentials(\n",
        "        impersonated_creds, target_audience=CR_URL\n",
        "    )\n",
        "\n",
        "    # Refresh to get a valid token\n",
        "    id_token_creds.refresh(request)\n",
        "\n",
        "    # Extract the token\n",
        "    id_token = id_token_creds.token\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        tasks = [send_request(session, index, latencies, id_token) for index in range(TOTAL_CONCURRENT_REQUESTS)]\n",
        "        results = await asyncio.gather(*tasks)\n",
        "\n",
        "        # Print responses\n",
        "        for r in results:\n",
        "            print(r)\n",
        "\n",
        "    # Compute P99 Latency\n",
        "    if latencies:\n",
        "        p99_latency = np.percentile(latencies, 99)\n",
        "        print(f\"P99 Latency: {p99_latency:.4f} seconds\")\n",
        "    else:\n",
        "        print(\"No latencies recorded.\")\n",
        "\n",
        "# Proper async handling in Jupyter Notebook\n",
        "await main()"
      ],
      "metadata": {
        "id": "UiOAL2-mZa9w"
      },
      "id": "UiOAL2-mZa9w",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "tgi_send_requests_to_cloudrun_async"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}